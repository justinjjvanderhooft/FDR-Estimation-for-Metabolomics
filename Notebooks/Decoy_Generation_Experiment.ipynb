{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoy Generation Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will re-produce the results from [here](file:///C:/Users/kia/Downloads/Metabolomics%20Internship/Papers/Converting%20from%20proteomics%20to%20metabolomics.pdf). In particular, we will produce the QQ-plots of q-values for FDR assessment, and histograms of estimated p-values for null model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms import Scores, Spectrum, Spikes\n",
    "from matchms.similarity import CosineGreedy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "ROOT = os.path.dirname(os.getcwd())\n",
    "sys.path.append(os.path.join(ROOT, 'Python_Files'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Decoy_Generation_Methods import get_parent_mass\n",
    "\n",
    "#Preliminary functions required for reproducing results\n",
    "\n",
    "\n",
    "#Function that produces an array of cosine scores (based on the greedy algorithm from matchms) from reference and query spectra\n",
    "\n",
    "def scores_array(query_spectra, reference_spectra, mass_tolerance = 1.0, cos_tolerance = 0.1):\n",
    "    \n",
    "    cosine_greedy = CosineGreedy(tolerance = cos_tolerance)\n",
    "    scores = []\n",
    "    for query in query_spectra:\n",
    "        \n",
    "        for reference in reference_spectra:\n",
    "            \n",
    "            score = cosine_greedy(query, reference)[0] if parent_mass_match(query, reference, mass_tolerance) else 0\n",
    "            scores += [cosine_greedy(query, reference)[0]]\n",
    "    return np.array(scores)\n",
    "\n",
    "#Function that returns True when two spectra have the same parentmass within a certain tolerance\n",
    "\n",
    "def parent_mass_match(spectrum_1, spectrum_2, tolerance):\n",
    "    \n",
    "    parent_mass_1 = spectrum_1.get(\"parent_mass\") if spectrum_1.get(\"parent_mass\") else get_parent_mass(spectrum_1)\n",
    "    parent_mass_2 = spectrum_2.get(\"parent_mass\") if spectrum_2.get(\"parent_mass\") else get_parent_mass(spectrum_2)\n",
    "    if parent_mass_1 == 0 or parent_mass_2 == 0:\n",
    "        return False\n",
    "    \n",
    "    elif abs(parent_mass_1 - parent_mass_2) <= tolerance:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pre-Processed Dataset \"AllPositive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.importing import load_from_json\n",
    "\n",
    "#Import pre-processed dataset\n",
    "\n",
    "\n",
    "\n",
    "ROOT = os.path.dirname(os.getcwd())\n",
    "path_data = os.path.join(ROOT, 'Data')\n",
    "sys.path.insert(0, ROOT)\n",
    "\n",
    "\n",
    "filename = os.path.join(path_data,'gnps_positive_ionmode_cleaned_by_matchms_and_lookups.json')\n",
    "spectra = load_from_json(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No of pre-processed target spectra\n",
    "\n",
    "print(f'No. of  pre-processed target spectra: {len(spectra)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matchms.filtering import normalize_intensities\n",
    "from matchms.filtering import require_minimum_number_of_peaks\n",
    "from matchms.filtering import select_by_mz\n",
    "from matchms.filtering import select_by_relative_intensity\n",
    "from matchms.filtering import reduce_to_number_of_peaks\n",
    "from matchms.filtering import add_losses\n",
    "\n",
    "from Additional_Post_Processing import window_process\n",
    "from Additional_Post_Processing import remove_spectra_within_tolerance\n",
    "from Additional_Post_Processing import remove_spectra_below\n",
    "from Additional_Post_Processing import remove_spectra_above_intensity\n",
    "\n",
    "#Post-processing dataset based on spec2vec post-processing and additional post-processing\n",
    "\n",
    "\n",
    "\n",
    "def post_process_s2v(s):\n",
    "    \n",
    "    s = normalize_intensities(s)\n",
    "    s = select_by_mz(s, mz_from=0, mz_to=1000)\n",
    "    s = require_minimum_number_of_peaks(s, n_required=10)\n",
    "    s = reduce_to_number_of_peaks(s, n_required=10, ratio_desired=0.5)\n",
    "    if s is None:\n",
    "        return None\n",
    "    s_remove_low_peaks = select_by_relative_intensity(s, intensity_from=0.001)\n",
    "    if len(s_remove_low_peaks.peaks) >= 10:\n",
    "        s = s_remove_low_peaks\n",
    "        \n",
    "    s = add_losses(s, loss_mz_from=5.0, loss_mz_to=200.0)\n",
    "    return s\n",
    "\n",
    "def additional_post_process(s):\n",
    "    \n",
    "    s = window_process(s, k = 6)\n",
    "    s = remove_spectra_within_tolerance(s)\n",
    "    s = remove_spectra_below(s)\n",
    "    if not s:\n",
    "        return None\n",
    "    \n",
    "    s = remove_spectra_above_intensity(s)\n",
    "    return s\n",
    "\n",
    "# apply post processing steps to the data\n",
    "spectra = [post_process_s2v(s) for s in spectra]\n",
    "spectra = [additional_post_process(s) for s in spectra if s is not None]\n",
    "\n",
    "# omit spectrums that didn't qualify for analysis\n",
    "spectra = [s for s in spectra if s is not None]\n",
    "target_spectra = spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No. of target spectra remaining after post-processing\n",
    "\n",
    "print(f'No. of  post-processed target spectra: {len(target_spectra)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Query Spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inchikeys = []\n",
    "for spec in target_spectra:\n",
    "    Inchikeys.append(spec.get(\"inchikey\"))\n",
    "    \n",
    "inchikeys_pd = pd.Series([x for x in Inchikeys if x])\n",
    "suitable_inchikeys = pd.DataFrame(inchikeys_pd.str[:14].value_counts()[inchikeys_pd.str[:14].value_counts().values >= 5])\n",
    "suitable_inchikeys.reset_index(level=suitable_inchikeys.index.names, inplace=True)\n",
    "suitable_inchikeys.columns = (['inchikey14', 'occurences'])\n",
    "\n",
    "# Important: sort values to make it reproducible (same occurences have random order otherwise!)\n",
    "suitable_inchikeys = suitable_inchikeys.sort_values(['occurences', 'inchikey14'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly select 1000 inchikeys that exist >=5 times in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_spectra = 1000\n",
    "\n",
    "np.random.seed(42) # to make it reproducible\n",
    "selection = np.random.choice(suitable_inchikeys.shape[0], num_spectra, replace=False)\n",
    "selected_inchikeys = suitable_inchikeys['inchikey14'].values[selection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly pick one spectra for each of the chosen inchikeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_spectra = []\n",
    "inchikeys_pd = pd.Series([x for x in Inchikeys])       #include all even empty ones to get the IDs right!\n",
    "\n",
    "np.random.seed(42)                        # to make it reproducible\n",
    "for inchikey in selected_inchikeys:\n",
    "    matches = inchikeys_pd[inchikeys_pd.str[:14] == inchikey].index.values\n",
    "    selected_spectra.append(int(np.random.choice(matches,1)[0]))\n",
    "    \n",
    "query_spectra = [target_spectra[i] for i in selected_spectra]\n",
    "print(f'No. of query spectra: {len(query_spectra)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove query spectra from target spectra\n",
    "\n",
    "target_spectra = [s for i, s in enumerate(target_spectra) if i not in selected_spectra]\n",
    "print(f'No. of target spectra remaining: {len(target_spectra)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Decoys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Decoy_Generation_Methods import naive_decoys\n",
    "from Decoy_Generation_Methods import spectrum_based_decoys\n",
    "from matchms.exporting import save_as_json\n",
    "\n",
    "#Create decoys based on the naive and spectrum-based method\n",
    "\n",
    "\n",
    "\n",
    "naive_decoy_spectra = naive_decoys(target_spectra)\n",
    "spectrum_based_decoy_spectra = spectrum_based_decoys(target_spectra)\n",
    "\n",
    "#Save decoy spectra\n",
    "\n",
    "save_as_json(naive_decoy_spectra, \"Naive_Decoy_Spectra\")\n",
    "save_as_json(spectrum_based_decoy_spectra, \"Spectrum_Based_Decoy_Spectra\")\n",
    "\n",
    "print(f'No. of decoy spectra created via the naive method: {len(naive_decoy_spectra)}')\n",
    "print(f'No. of decoy spectra created via the spectrum based method: {len(spectrum_based_decoy_spectra)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDR Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimating FDRs for 1000 query spectrum for 100 different cosine score thresholds\n",
    "\n",
    "\n",
    "\n",
    "#quey_spectra is list of query spectra (from target database)\n",
    "#target_spectra is list of target spectra (target database)\n",
    "#decoy_spectra is list of decoy spectra (decoy database)\n",
    "#Assume all necessary processing is done.\n",
    "\n",
    "score_thresholds = np.arange(0, 1, 0.01)                 #Using 100 score thresholds\n",
    "\n",
    "#Getting hits for each query spectrum in reference spectra\n",
    "#Type_query here is whether it's target or decoy hit. True is for target hit, False for decoy hit.\n",
    "\n",
    "def get_hits(query_spectra, reference_spectra, cos_tolerance, type_hit):\n",
    "    \n",
    "    no_query = len(query_spectra)\n",
    "    hits = pd.DataFrame({'Cosine Score':pd.Series([0]*no_query, dtype='float'), 'Reference InChl':pd.Series([0]*no_query, dtype='str'), 'Reference Id':pd.Series([0]*no_query, dtype='str'), 'Query InChl':pd.Series([0]*no_query, dtype='str'), 'Query Id':pd.Series([0]*no_query, dtype='str'), 'Target/Decoy Hit':pd.Series([0]*no_query, dtype='bool')})\n",
    "    for i in range(no_query):\n",
    "    \n",
    "        query_scores = scores_array([query_spectra[i]], reference_spectra, cos_tolerance = cos_tolerance)\n",
    "        max_reference = np.argsort(query_scores)[-1]\n",
    "        reference_inchikey = reference_spectra[max_reference].get(\"inchikey\")\n",
    "        reference_inchikey = reference_inchikey if reference_inchikey else np.nan\n",
    "        reference_id = reference_spectra[max_reference].get(\"spectrumid\")\n",
    "        reference_id = reference_id if reference_id else np.nan\n",
    "        query_inchikey = query_spectra[i].get(\"inchikey\")           \n",
    "        query_id = query_spectra[i].get(\"spectrumid\")\n",
    "        \n",
    "        hit = [query_scores[max_reference], reference_inchikey, reference_id, query_inchikey, query_id, type_hit]\n",
    "        hits.iloc[i, :] = hit                 \n",
    "    return hits\n",
    "\n",
    "#Estimate FDR from dataframe of sorted hits for certain cosine score threshold\n",
    "#FDR is estimated as no. decoy hits above threshold/no. target hits above threshold\n",
    "#Returns np.nan if no. targets is 0\n",
    "\n",
    "def estimate_FDR(hits, threshold):\n",
    "    \n",
    "    thresholds_hits = hits[hits[\"Cosine Score\"] > threshold]\n",
    "    targets = sum(thresholds_hits[\"Target/Decoy Hit\"] == 1)\n",
    "    decoys = sum(thresholds_hits[\"Target/Decoy Hit\"] == 0)\n",
    "    if targets != 0 :\n",
    "        \n",
    "        FDR_estimate = decoys/targets\n",
    "        return FDR_estimate\n",
    "    else:\n",
    "        \n",
    "        print(\"No targets found. No FDR estimate available.\")\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "#Naive decoy hits\n",
    "\n",
    "naive_decoy_hits = get_hits(query_spectra, naive_decoy_spectra, cos_tolerance = 0.005, type_hit = False)\n",
    "target_hits = get_hits(query_spectra, target_spectra, cos_tolerance = 0.005, type_hit = True)\n",
    "naive_all_hits = pd.concat([naive_decoy_hits, target_hits], ignore_index = True)\n",
    "naive_all_hits = naive_all_hits.sort_values(by = [\"Cosine Score\"], ascending= False)\n",
    "\n",
    "#Spectrum-based decoy hits\n",
    "\n",
    "spectrum_based_decoy_hits = get_hits(query_spectra, spectrum_based_decoy_spectra, cos_tolerance = 0.005, type_hit = False)\n",
    "spectrum_based_all_hits = pd.concat([spectrum_based_decoy_hits, target_hits], ignore_index = True)\n",
    "spectrum_based_all_hits = spectrum_based_all_hits.sort_values(by = [\"Cosine Score\"], ascending= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Q-Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimating q-values for target and decoy hits for query spectra \n",
    "#(Using both the naive and spectrum-based method of decoy generartion)\n",
    "\n",
    "\n",
    "\n",
    "#For the naive method\n",
    "#Going through each hit from all hits, and find their q-value:\n",
    "#Go through all the possible score thresholds.\n",
    "#Calculate their FDRs.\n",
    "#The min. FDR at which this hit is in the output list is the q-value.\n",
    "\n",
    "naive_estimated_q_values = []\n",
    "for index, hit in naive_all_hits.iterrows():\n",
    "    \n",
    "    estimate_FDRs = []\n",
    "    hit_score = hit[\"Cosine Score\"]\n",
    "    thresholds = score_thresholds[score_thresholds < hit_score]\n",
    "    for threshold in thresholds:\n",
    "        \n",
    "        FDR = estimate_FDR(naive_all_hits, threshold)\n",
    "        if not np.isnan(FDR):\n",
    "            \n",
    "            estimate_FDRs += [FDR]    \n",
    "    if estimate_FDRs != []:\n",
    "\n",
    "        naive_estimated_q_values += [min(estimate_FDRs)]\n",
    "    else:\n",
    "        \n",
    "        naive_estimated_q_values += [np.nan]\n",
    "        \n",
    "#For the spectrum-based method\n",
    "#Going through each hit from all hits, and find their q-value:\n",
    "#Go through all the possible score thresholds.\n",
    "#Calculate their FDRs.\n",
    "#The min. FDR at which this hit is in the output list is the q-value.\n",
    "\n",
    "spectrum_based_estimated_q_values = []\n",
    "for index, hit in spectrum_based_all_hits.iterrows():\n",
    "    \n",
    "    estimate_FDRs = []\n",
    "    hit_score = hit[\"Cosine Score\"]\n",
    "    thresholds = score_thresholds[score_thresholds < hit_score]\n",
    "    for threshold in thresholds:\n",
    "        \n",
    "        FDR = estimate_FDR(naive_all_hits, threshold)\n",
    "        if not np.isnan(FDR):\n",
    "            \n",
    "            estimate_FDRs += [FDR]    \n",
    "    if estimate_FDRs != []:\n",
    "\n",
    "        spectrum_based_estimated_q_values += [min(estimate_FDRs)]\n",
    "    else:\n",
    "        \n",
    "        spectrum_based_estimated_q_values += [np.nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating True FDRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating True FDRs\n",
    "\n",
    "\n",
    "    \n",
    "#Calculate FDR from dataframe of sorted hits for certain cosine score threshold\n",
    "#False hits are hits which are not the true identity for associated query spectra\n",
    "#FDR is estimated as no. false hits/no. target hits above threshold\n",
    "#Returns np.nan if no. targets is 0\n",
    "\n",
    "def calculate_FDR(hits, threshold):\n",
    "    \n",
    "    thresholds_hits = hits[hits[\"Cosine Score\"] > threshold]\n",
    "    no_targets = sum(thresholds_hits[\"Target/Decoy Hit\"] == 1)\n",
    "    target_hits = thresholds_hits[thresholds_hits[\"Target/Decoy Hit\"] == 1]\n",
    "    no_false_hits = sum(target_hits[\"Reference InChl\"] != target_hits[\"Query InChl\"])\n",
    "    if no_targets != 0:\n",
    "        \n",
    "        FDR = no_false_hits/no_targets\n",
    "        return FDR\n",
    "    else:\n",
    "        \n",
    "        print(\"No targets found. No FDR estimate available.\")\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating True Q-Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating true q-values for target and decoy hits for query spectra\n",
    "#(Using both the naive and spectrum-based decoy generation methods)\n",
    "\n",
    "\n",
    "\n",
    "#For the naive method\n",
    "#Going through each hit from all hits, and find their true q-value:\n",
    "#Go through all the possible score thresholds.\n",
    "#Calculate their true FDRs.\n",
    "#The min. FDR at which this hit is in the output list is the q-value.\n",
    "\n",
    "naive_true_q_values = []\n",
    "for index, hit in naive_all_hits.iterrows():\n",
    "    \n",
    "    true_FDRs = []\n",
    "    hit_score = hit[\"Cosine Score\"]\n",
    "    thresholds = score_thresholds[score_thresholds < hit_score]\n",
    "    for threshold in thresholds:\n",
    "        \n",
    "        FDR = calculate_FDR(naive_all_hits, threshold)\n",
    "        if not np.isnan(FDR):\n",
    "            \n",
    "            true_FDRs += [FDR]    \n",
    "    if true_FDRs != []:\n",
    "\n",
    "        naive_true_q_values += [min(true_FDRs)]\n",
    "    else:\n",
    "        \n",
    "        naive_true_q_values += [np.nan]\n",
    "        \n",
    "#For specturm-based method\n",
    "#Going through each hit from all hits, and find their true q-value:\n",
    "#Go through all the possible score thresholds.\n",
    "#Calculate their true FDRs.\n",
    "#The min. FDR at which this hit is in the output list is the q-value.\n",
    "\n",
    "spectrum_based_true_q_values = []\n",
    "for index, hit in spectrum_based_all_hits.iterrows():\n",
    "    \n",
    "    true_FDRs = []\n",
    "    hit_score = hit[\"Cosine Score\"]\n",
    "    thresholds = score_thresholds[score_thresholds < hit_score]\n",
    "    for threshold in thresholds:\n",
    "        \n",
    "        FDR = calculate_FDR(spectrum_based_all_hits, threshold)\n",
    "        if not np.isnan(FDR):\n",
    "            \n",
    "            true_FDRs += [FDR]    \n",
    "    if true_FDRs != []:\n",
    "\n",
    "        spectrum_based_true_q_values += [min(true_FDRs)]\n",
    "    else:\n",
    "        \n",
    "        spectrum_based_true_q_values += [np.nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QQ-plots of True Q-Values vs. Esimated Q-Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting q-values and removing nas.\n",
    "\n",
    "\n",
    "\n",
    "#For naive method\n",
    "\n",
    "naive_estimated_q_values = np.array(naive_estimated_q_values)\n",
    "naive_true_q_values = np.array(naive_true_q_values)\n",
    "order = np.argsort(naive_estimated_q_values)\n",
    "naive_estimated_q_values = naive_estimated_q_values[order]\n",
    "naive_true_q_values = naive_true_q_values[order]\n",
    "\n",
    "naive_estimated_non_nans = np.where(~np.isnan(naive_estimated_q_values))[0]\n",
    "naive_true_non_nans = np.where(~np.isnan(naive_true_q_values))[0]\n",
    "naive_non_nans = np.intersect1d(naive_estimated_non_nans, naive_true_non_nans, assume_unique = True)\n",
    "naive_estimated_q_values = naive_estimated_q_values[naive_non_nans]\n",
    "naive_true_q_values = naive_true_q_values[naive_non_nans]\n",
    "\n",
    "\n",
    "#For spectrum-based method\n",
    "\n",
    "spectrum_based_estimated_q_values = np.array(spectrum_based_estimated_q_values)\n",
    "spectrum_based_true_q_values = np.array(spectrum_based_true_q_values)\n",
    "order = np.argsort(spectrum_based_estimated_q_values)\n",
    "spectrum_based_estimated_q_values = spectrum_based_estimated_q_values[order]\n",
    "spectrum_based_true_q_values = spectrum_based_true_q_values[order]\n",
    "\n",
    "spectrum_based_estimated_non_nans = np.where(~np.isnan(spectrum_based_estimated_q_values))[0]\n",
    "spectrum_based_true_non_nans = np.where(~np.isnan(spectrum_based_true_q_values))[0]\n",
    "spectrum_based_non_nans = np.intersect1d(spectrum_based_estimated_non_nans, spectrum_based_true_non_nans, assume_unique = True)\n",
    "spectrum_based_estimated_q_values = spectrum_based_estimated_q_values[spectrum_based_non_nans]\n",
    "spectrum_based_true_q_values = spectrum_based_true_q_values[spectrum_based_non_nans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QQ-plots of true qq-values against estimated q-values.\n",
    "#For both the naive and spectrum-based methods of decoy generation\n",
    "\n",
    "\n",
    "\n",
    "#Producing QQ-plot for the two decoy methods.\n",
    "\n",
    "xmax = np.max(np.concatenate((naive_estimated_q_values, spectrum_based_estimated_q_values)))\n",
    "ymax = np.max(np.concatenate((naive_true_q_values, spectrum_based_true_q_values)))\n",
    "ax_lim = xmax if xmax > ymax else ymax \n",
    "\n",
    "fig=plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "#ax.scatter(naive_true_q_values, naive_estimated_q_values, color = \"r\", s=20)\n",
    "#ax.scatter(spectrum_based_true_q_values, spectrum_based_estimated_q_values, color = \"b\", s=20)\n",
    "ax.plot(naive_true_q_values, naive_estimated_q_values, color = \"r\", label = \"Naive Method\")\n",
    "ax.plot(spectrum_based_true_q_values, spectrum_based_estimated_q_values, color = \"b\", label = \"Spectrum-Based Method\")\n",
    "ax.plot([0, ax_lim], [0,ax_lim],\"r--\", color = \"black\")\n",
    "\n",
    "#ax.set_xlim(0, ax_lim)\n",
    "#ax.set_ylim(0, ax_lim)\n",
    "ax.set_ylabel('Estimated q-values')\n",
    "ax.set_xlabel('True q-values')\n",
    "ax.set_title('QQ-plot of True Q-Values vs. Estimated Q-Values')\n",
    "ax.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
